# Value_Reasoning_Reliability
This project introduces a framework for evaluating the value reasoning reliability of small Large Language Models (sLLMs), focusing on consistency, robustness, and stability across varied prompts and tasks. Our benchmarks reveal significant output randomness and gaps in stable value reasoning, highlighting directions for improvement.
